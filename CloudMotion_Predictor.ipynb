{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d6bc52",
   "metadata": {},
   "source": [
    "# ☁️ INSAT-3DR Cloud Motion Forecasting\n",
    "\n",
    "This notebook demonstrates a multi-channel (TIR1 + WV) short-term cloud motion prediction using a 3D U-Net with SE blocks and LPIPS-SSIM-enhanced loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f75d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lpips scikit-image pytorch-msssim\n",
    "import os, zipfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
    "import lpips\n",
    "from pytorch_msssim import ssim as ssim_loss_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c84d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "zip_path = \"/content/data.zip\"\n",
    "extract_dir = \"/content/data\"\n",
    "if not os.path.exists(extract_dir):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a28a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/content/data\"\n",
    "channels = [\"TIR1\", \"WV\"]\n",
    "for ch in channels:\n",
    "    ch_path = os.path.join(base_path, ch)\n",
    "    files = sorted([f for f in os.listdir(ch_path) if f.endswith(\".tif\")])\n",
    "    print(f\"{ch}: {len(files)} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e160fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESIZE = (128, 128)\n",
    "CHANNELS = [\"TIR1\", \"WV\"]\n",
    "BASE_PATH = \"/content/data\"\n",
    "\n",
    "def normalize_tensor(t):\n",
    "    return (t - t.mean()) / (t.std() + 1e-5)\n",
    "\n",
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, base_path):\n",
    "        self.X, self.Y = [], []\n",
    "        self._load(base_path)\n",
    "\n",
    "    def _load(self, base_path):\n",
    "        files = {ch: sorted([os.path.join(base_path, ch, f) for f in os.listdir(os.path.join(base_path, ch)) if f.endswith(\".tif\")]) for ch in CHANNELS}\n",
    "        for i in [0, 2, 4]:\n",
    "            x_stack, y_stack = [], []\n",
    "            for ch in CHANNELS:\n",
    "                imgs = [Image.open(files[ch][j]).convert(\"L\") for j in range(i, i+5)]\n",
    "                tensors = [normalize_tensor(transforms.ToTensor()(transforms.Resize(RESIZE)(img))) for img in imgs]\n",
    "                x_stack.append(torch.stack(tensors[:3]))\n",
    "                y_stack.append(torch.stack(tensors[3:]))\n",
    "            self.X.append(torch.stack(x_stack, dim=1))\n",
    "            self.Y.append(torch.stack(y_stack, dim=1))\n",
    "\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.Y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11929a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _, _ = x.size()\n",
    "        y = self.pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels=2, out_channels=2):\n",
    "        super().__init__()\n",
    "        self.down1 = nn.Sequential(nn.Conv3d(in_channels, 32, 3, padding=1), nn.BatchNorm3d(32), nn.ReLU(), SEBlock(32))\n",
    "        self.down2 = nn.Sequential(nn.Conv3d(32, 64, 3, padding=1), nn.BatchNorm3d(64), nn.ReLU(), SEBlock(64))\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "        self.middle = nn.Sequential(nn.Conv3d(64, 128, 3, padding=1), nn.BatchNorm3d(128), nn.ReLU(), SEBlock(128))\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"trilinear\", align_corners=False)\n",
    "        self.up1 = nn.Sequential(nn.Conv3d(128, 64, 3, padding=1), nn.BatchNorm3d(64), nn.ReLU())\n",
    "        self.up2 = nn.Sequential(nn.Conv3d(64, 32, 3, padding=1), nn.BatchNorm3d(32), nn.ReLU())\n",
    "        self.out = nn.Conv3d(32, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.down1(x)\n",
    "        x2 = self.down2(self.pool(x1))\n",
    "        m = self.middle(x2)\n",
    "        x3 = self.up1(self.up(m))\n",
    "        x4 = self.up2(x3)\n",
    "        return torch.tanh(self.out(x4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc52da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp = lpips.LPIPS(net='alex').to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.lpips = lpips.LPIPS(net='alex').to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        mse_loss = self.mse(pred, target)\n",
    "        ssim_total = 0.0\n",
    "        lpips_total = 0.0\n",
    "        N, C, T, H, W = pred.shape\n",
    "\n",
    "        for t in range(T):\n",
    "            for c in range(C):\n",
    "                pr = pred[:, c, t]\n",
    "                gt = target[:, c, t]\n",
    "                ssim_val = ssim_loss_fn(pr.unsqueeze(1), gt.unsqueeze(1), data_range=1.0)\n",
    "                ssim_total += (1 - ssim_val)\n",
    "                pr_rgb = pr.repeat(1, 3, 1, 1)\n",
    "                gt_rgb = gt.repeat(1, 3, 1, 1)\n",
    "                lpips_val = self.lpips(pr_rgb, gt_rgb)\n",
    "                lpips_total += lpips_val.mean()\n",
    "\n",
    "        return mse_loss + 0.1 * (ssim_total / (C * T)) + 0.1 * (lpips_total / (C * T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd248a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EPOCHS, LR, BATCH_SIZE = 200, 1e-4, 1\n",
    "dataset = CloudDataset(BASE_PATH)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "model = UNet3D().to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', patience=10, factor=0.5, verbose=True)\n",
    "loss_fn = CombinedLoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        xb = xb.squeeze(3).permute(0, 2, 1, 3, 4)\n",
    "        yb = yb.squeeze(3).permute(0, 2, 1, 3, 4)\n",
    "        opt.zero_grad()\n",
    "        out = model(xb)\n",
    "        loss = loss_fn(out, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss/len(loader):.4f}\")\n",
    "    scheduler.step(total_loss/len(loader))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
